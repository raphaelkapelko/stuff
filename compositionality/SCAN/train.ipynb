{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython import get_ipython\n",
    "if get_ipython() is not None:\n",
    "    base_dir = get_ipython().run_line_magic('pwd', '')\n",
    "else:\n",
    "    base_dir = os.getcwd()\n",
    "sys.path.insert(0, str(base_dir))\n",
    "import load\n",
    "import torch as tch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696f1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worker1(dict, list):\n",
    "    l = len(list)\n",
    "    if l in dict:\n",
    "        dict[l]+=1\n",
    "    else:\n",
    "        dict[l] = 1\n",
    "def collect(data, worker):\n",
    "    result = dict()\n",
    "    for i in data:\n",
    "        worker(result, i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arch\n",
    "lr = 2e-3\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.emb_dim_in = 64\n",
    "        self.emb_dim_out = 16\n",
    "        self.in_vocab_embeddings = tch.randn((load.in_vocab_size, self.emb_dim_in))\n",
    "        self.out_vocab_embeddings = tch.randn((load.out_vocab_size, self.emb_dim_out))\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def vectorize(self, data_chunk):\n",
    "        max_len = max([len(line) for line in data_chunk])\n",
    "        in_ = tch.zeros((len(data_chunk), max_len, self.emb_dim_in))\n",
    "        for line_idx, line in enumerate(data_chunk):\n",
    "            for word_idx, word in enumerate(line):\n",
    "                in_[line_idx, word_idx] = self.in_vocab_embeddings[word]\n",
    "        return in_\n",
    "\n",
    "def init_model(arch, LR):\n",
    "    mod = arch()\n",
    "    return mod, optim.Adam(mod.parameters(), LR)\n",
    "\n",
    "model, optimizer = init_model(LSTM, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_BATCHES = 1000# ~10 epochs\n",
    "BATCH_SIZE = 200\n",
    "for b in range(TRAIN_BATCHES):\n",
    "    batch_data_in = load.encoded_in[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "    batch_data_out = load.encoded_out[b*BATCH_SIZE:(b+1)*BATCH_SIZE]\n",
    "    batch_data_in_vectorized = model.vectorize(batch_data_in)\n",
    "    with tch.no_grad():\n",
    "        model.zero_grad()\n",
    "    #forward\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
